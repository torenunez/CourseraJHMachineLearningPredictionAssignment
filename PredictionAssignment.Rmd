---
title: "Prediction Assignment"
author: "Salvador J Nunez"
date: "December 27, 2015"
output: html_document
---

##Summary

Subjects using wearable devices (Jawbone Up, Nike FuelBand, FitBit, etc.) are asked to perform barbell lifts. Five different ways (correct and incorrect) of performing the exercise are categorized in "classes". Machine learning techniques are used to recognize and predict these "classes" . After separating the training data set into training and validation subsets, models based on regression trees and random forests are attempted and analyzed. While regression trees produced an acccuracy of 49%, random forests yieled an accuracy over 99%. Thus, the random forest model is used on the testing data set and used for the submission.


##Analysis

First, we take care of some general housekeeping by downloading the required packages. 
```{r setup, echo = FALSE}

##load packages and define functions
library(caret)
library(rpart)
```

Second, we download and load the data into a seperate folder in the working directory.
```{r load data,}
##set URLs and files
trainingUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingFile <- "./data/pml-training.csv"
testingFile  <- "./data/pml-testing.csv"

##create folders and download files
if (!file.exists("./data")) {dir.create("./data")}
if (!file.exists(trainingFile)) {download.file(trainingUrl, destfile=trainingFile, method="curl")}
if (!file.exists(testingFile)) {download.file(testingUrl, destfile=testingFile, method="curl")}

##read data
training <- read.csv(trainingFile, na.strings=c("NA",""))
testing <-read.csv(testingFile, na.strings=c("NA",""))
```

Then, clean the data to reduce the noise and further partition the training data set for validation. 
```{r clean data,}

##Clean Training
columnNACounts <- colSums(is.na(training))     
NAcols <- columnNACounts >= nrow(training)*0.9          
CleanTraining <- training[!NAcols]     
CleanTraining <- CleanTraining[, c(7:60)] 

##Clean Testing
columnNACounts <- colSums(is.na(testing))       
NAcols <- columnNACounts >= nrow(testing)*0.9               
CleanTesting <- testing[!NAcols]       
CleanTesting <- CleanTesting[, c(7:60)] 

##Partition and create Validation
inTrain <- createDataPartition(y = CleanTraining$classe, p = 0.6, list = FALSE)
PureTrainingData <- CleanTraining[inTrain, ]
ValidationData <- CleanTraining[-inTrain, ]
```

First, we fit a model using recursive partitioning and regression trees and inspect the confusion matrix on the validation data set. 
```{r repart,}
##Train
RPartTrainFit <- train(classe~., data=PureTrainingData, method="rpart")

##Validate
predictRPart <- predict(RPartTrainFit, ValidationData)
confusionMatrix(predictRPart,ValidationData$classe)
RPartErrorRate = 1 - confusionMatrix(predictRPart,ValidationData$classe)$overall[1]
```

Then, we fit the model to a random forest to see if we obtain better accuracy.
```{r random forests,}
##Train
RFtrainFit <- train(classe ~ ., data = PureTrainingData, method = "rf", prox = TRUE, 
               trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE))

##Validate
predictRFval <- predict(RFtrainFit, ValidationData)
confusionMatrix(ValidationData$classe, predictRFval)
RFErrorRate = 1 - confusionMatrix(ValidationData$classe, predictRFval)$overall[1]
```

Random forests provide near perfect accuracy in the validation data set with an error rate of ` r RFErrorRate`. Whereas regression trees misclassify classe "C" and yielded an error rate of ` r RPartTrainFit`.   Instead of improving the accuracy for the regression trees, we cautiously use the random forest model for the test. The near perfect accuracy is suspect and may reflect some overfitting.

Finally, apply the model(s) to the test data set. Both models are used, to see how different the results are. However, only the random forest predictions are saved in the test result files and used for submission.
```{r submission,}

##Predict
predict(RPartTrainFit, newdata=CleanTesting)
predict(RFtrainFit, newdata=CleanTesting)
FinalTestPredictions <- predict(RFtrainFit, newdata=CleanTesting)


#Write files with coursera function
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(FinalTestPredictions)

```
